2026-01-31 18:15:35
"C:\wamp64\www\freshness/.venv/Scripts/python.exe" "C:\wamp64\www\freshness/model_predict.py" "C:\wamp64\www\freshness/uploads/2026-01-31-18-14-49-.jpg" 2>&1

0: 480x640 1 Pork, 1 Spoiled Beef, 32191.2ms
Speed: 14.5ms preprocess, 32191.2ms inference, 35.8ms postprocess per image at shape (1, 3, 480, 640)
done


2026-01-31 18:37:52
"C:\wamp64\www\freshness/.venv/Scripts/python.exe" "C:\wamp64\www\freshness/model_predict.py" "C:\wamp64\www\freshness/uploads/2026-01-31-18-37-17-.jpg" 2>&1
Traceback (most recent call last):
  File "C:\wamp64\www\freshness/model_predict.py", line 20, in <module>
    results = model.predict(img, device='cpu', imgsz=640, half=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\wamp64\www\freshness\.venv\Lib\site-packages\ultralytics\engine\model.py", line 529, in predict
    self.predictor.setup_model(model=self.model, verbose=is_cli)
  File "C:\wamp64\www\freshness\.venv\Lib\site-packages\ultralytics\engine\predictor.py", line 395, in setup_model
    self.model = AutoBackend(
                 ^^^^^^^^^^^^
  File "C:\wamp64\www\freshness\.venv\Lib\site-packages\torch\utils\_contextlib.py", line 124, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\wamp64\www\freshness\.venv\Lib\site-packages\ultralytics\nn\autobackend.py", line 223, in __init__
    model = model.fuse(verbose=verbose)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\wamp64\www\freshness\.venv\Lib\site-packages\ultralytics\nn\tasks.py", line 236, in fuse
    m.conv = fuse_conv_and_bn(m.conv, m.bn)  # update conv
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\wamp64\www\freshness\.venv\Lib\site-packages\ultralytics\utils\torch_utils.py", line 256, in fuse_conv_and_bn
    conv.weight.data = torch.mm(w_bn, w_conv).view(conv.weight.shape)
                       ^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: [enforce fail at alloc_cpu.cpp:117] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2359296 bytes.


